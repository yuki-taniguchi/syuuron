{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (3.19.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.20.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\baseb\\anaconda3\\envs\\convenient\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "max_samples = 0.5\n",
    "select_data = 'abalone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baseb\\.keras\\datasets\\abalone.data\n"
     ]
    }
   ],
   "source": [
    "if select_data == 'letter':\n",
    "    # データの取得\n",
    "    df = pd.read_csv('../data/letter_recognition.csv', header=None)\n",
    "\n",
    "    # Aのみを判定するため，Aを0，A以外を1にした．\n",
    "    # 少数派のAを正常，その他を異常データと定義\n",
    "    df[0] = df[0].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "    #Xとyを入力\n",
    "    X = df[range(1,17)]\n",
    "    y = df[0]\n",
    "\n",
    "elif select_data == 'wine':\n",
    "    \n",
    "    dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "\n",
    "    # ファイルのダウンロード\n",
    "    dataset_path = tf.keras.utils.get_file('wine.data', dataset_url)\n",
    "\n",
    "    print(dataset_path)\n",
    "\n",
    "    column_names = ['Alcohol',\n",
    "    'Malic acid',\n",
    "    'Ash',\n",
    "    'Alcalinity of ash',\n",
    "    'Magnesium',\n",
    "    'Total phenols',\n",
    "    'Flavanoids',\n",
    "    'Nonflavanoid phenols',\n",
    "    'Proanthocyanins',\n",
    "    'Color intensity',\n",
    "    'Hue',\n",
    "    'OD280/OD315 of diluted wines',\n",
    "    'Proline' \n",
    "    ]\n",
    "\n",
    "    raw_data = pd.read_csv(dataset_path, names=column_names)\n",
    "    raw_data['y'] = raw_data.index\n",
    "    raw_data = raw_data.reset_index(drop=True)\n",
    "\n",
    "    raw_data['y'] = raw_data['y'].apply(lambda x: 0 if x == 3 else 1)\n",
    "\n",
    "    X = raw_data.drop('y', axis=1)\n",
    "    y = raw_data['y']\n",
    "\n",
    "elif select_data == 'abalone':\n",
    "\n",
    "    dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "\n",
    "    # ファイルのダウンロード\n",
    "    dataset_path = tf.keras.utils.get_file('abalone.data', dataset_url)\n",
    "\n",
    "    print(dataset_path)\n",
    "\n",
    "    raw_data = pd.read_csv(dataset_path, names=range(8)).reset_index(drop=True)\n",
    "\n",
    "    raw_data[7] = raw_data[7].apply(lambda x: 1 if x > 4 else 0)\n",
    "\n",
    "\n",
    "    X = raw_data.drop(7, axis=1)\n",
    "    y = raw_data[7]\n",
    "\n",
    "else:\n",
    "    print('そのデータはありません')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要な関数の定義\n",
    "\n",
    "# 共分散行列の逆行列\n",
    "def inv_cov(Z):\n",
    "    #標準化後のベクトルを入力する\n",
    "    #標準化した後なので相関行列と分散共分散行列は一致する\n",
    "    c = np.cov(Z.T)\n",
    "    return np.linalg.inv(c)\n",
    "\n",
    "#マハラノビス汎距離\n",
    "def cal_MD(Z, inv_C):\n",
    "    '''\n",
    "    Z:標準化したベクトル\n",
    "    inv_C:標準化後の共分散行列\n",
    "    '''\n",
    "    MD = np.zeros(len(Z))\n",
    "    for i in range(len(Z)):\n",
    "        _a = np.dot(Z[i], inv_C)\n",
    "        _MD = np.dot(_a, Z[i].T)\n",
    "        _MD = _MD / Z.shape[1]\n",
    "        MD[i] = _MD\n",
    "    return MD\n",
    "\n",
    "# MTSを実行\n",
    "def fit_MTS(X, y):\n",
    "    \n",
    "    # 正常データのみを使用して標準化\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X[y == 0])\n",
    "    normal_Z = scaler.transform(X[y == 0])\n",
    "    anomaly_Z = scaler.transform(X[y == 1])\n",
    "\n",
    "    # 正常データのみを使用して共分散行列を計算\n",
    "    inv_C = inv_cov(normal_Z)\n",
    "\n",
    "    # いったん飛ばす，削除の基準は？削除しない方法もあるっぽい？\n",
    "        #１度目の仮のマハラノビス距離を計算\n",
    "        # MD_1st = cal_MD(normal_Z, inv_C)\n",
    "        # もしもマハラノビス距離が余りにも大きいサンプルがあれば任意で削除する\n",
    "        # 削除後のデータを使用して標準化と共分散行列を計算\n",
    "\n",
    "    # 異常データと直交表を用いてSN比を計算\n",
    "    #L8直行表\n",
    "    l8 = np.array([\n",
    "        [1,1,1,1,1,1,1],\n",
    "        [1,1,1,2,2,2,2],\n",
    "        [1,2,2,1,1,2,2],\n",
    "        [1,2,2,2,2,1,1],\n",
    "        [2,1,2,1,2,1,2],\n",
    "        [2,1,2,2,1,2,1],\n",
    "        [2,2,1,1,2,2,1],\n",
    "        [2,2,1,2,1,1,2]\n",
    "        ])\n",
    "    l8 = (l8 == 1)\n",
    "\n",
    "    #異常データのマハラノビス距離\n",
    "    result = np.zeros((l8.shape[0], anomaly_Z.shape[0]))\n",
    "    for i, l8_row in enumerate(l8):\n",
    "        result[i] = cal_MD(anomaly_Z[:, l8_row], inv_C[l8_row][:,l8_row])\n",
    "\n",
    "    #SN比\n",
    "    sn = np.zeros(l8.shape[0])\n",
    "    for idx, row in enumerate(result):\n",
    "        sum_MD = 0\n",
    "        for i in range(len(row)):\n",
    "            sum_MD += 1 / row[i]\n",
    "        sn[idx] = -10 * math.log10(sum_MD / len(row))\n",
    "        \n",
    "    # SN比を利用し，不要と思われる変数を削除する\n",
    "    #変数選択\n",
    "    df_sn = pd.DataFrame(index=X.columns, columns=['SN比','残す'])\n",
    "    for i, clm in enumerate(X.columns):\n",
    "        df_sn.loc[df_sn.index == clm, 'SN比'] = sum(sn[l8.T[i]]) - sum(sn[~l8.T[i]])\n",
    "        df_sn.loc[df_sn.index == clm, '残す'] = sum(sn[l8.T[i]]) - sum(sn[~l8.T[i]]) > 0\n",
    "    #使用した変数を保存\n",
    "    select_columns = df_sn[df_sn['残す']].index\n",
    "    \n",
    "    if len(select_columns) > 1:\n",
    "        # 選択変数でのスケーラーと共分散行列を計算\n",
    "        result_scaler = StandardScaler()\n",
    "        result_scaler.fit(X[select_columns][y == 0])\n",
    "        result_Z = result_scaler.transform(X[select_columns][y == 0])\n",
    "        result_inv_C = inv_cov(result_Z)\n",
    "    else:\n",
    "        select_columns = df_sn['SN比'].astype(float).idxmax()\n",
    "        result_scaler = 0\n",
    "        result_inv_C = 0\n",
    "\n",
    "    # 単位空間のスケーラーと共分散行列と選択した変数を出力\n",
    "    return result_scaler, result_inv_C, select_columns\n",
    "\n",
    "# 新しいデータのマハラノビス距離を計算する\n",
    "def predict_MTS(X, scaler, inv_C, select_columns):\n",
    "    Z = scaler.transform(X[select_columns])\n",
    "    MD = cal_MD(Z, inv_C)\n",
    "    return MD\n",
    "\n",
    "# 閾値をジニ係数が最小になるように決定する\n",
    "def determine_threshold(y_true, y_pred):\n",
    "    df_pred = pd.DataFrame(y_true)\n",
    "    df_pred['pred'] = y_pred\n",
    "    df_pred = df_pred.sort_values('pred').reset_index(drop=True)\n",
    "\n",
    "    min_gini = np.inf\n",
    "    threshold = 0\n",
    "    for i in range(len(df_pred)):\n",
    "        \n",
    "        neg = df_pred.iloc[:i+1]\n",
    "        pos = df_pred.iloc[i:]\n",
    "\n",
    "        p_neg = sum(neg[y_true.name]) / len(neg)\n",
    "        gini_neg = 1 - ( p_neg ** 2 + ( 1 - p_neg ) ** 2 )\n",
    "\n",
    "        p_pos = sum(pos[y_true.name]) / len(pos)\n",
    "        gini_pos = 1 - ( p_pos ** 2 + ( 1 - p_pos ) ** 2 )\n",
    "\n",
    "        gini_split = (len(neg) / len(df_pred) * gini_neg) + (len(pos) / len(df_pred) * gini_pos)\n",
    "\n",
    "        if min_gini > gini_split:\n",
    "            min_gini = gini_split\n",
    "            threshold = df_pred.iloc[i]['pred']\n",
    "            threshold_idx = i\n",
    "\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Best paramater')\n",
    "    print(threshold_idx, min_gini, threshold)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    print('AUC : ', roc_auc_score(y_true.values, y_pred))\n",
    "\n",
    "    recall = df_pred.iloc[threshold_idx + 1:][y_true.name].sum() / df_pred[y_true.name].sum()\n",
    "    print('recall : ', recall)\n",
    "\n",
    "    precision = df_pred.iloc[threshold_idx + 1:][y_true.name].mean()\n",
    "    print('precision :', precision)\n",
    "\n",
    "    g_mean = np.sqrt(recall * precision)\n",
    "    print('g_mean : ', g_mean)\n",
    "\n",
    "    RS = recall / precision\n",
    "    print('RS : ', RS)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:06,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "54 0.022349285415097658 0.0895\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.990579760741051\n",
      "recall :  0.9887585532746823\n",
      "precision : 0.9950811608460404\n",
      "g_mean :  0.991914819422022\n",
      "RS :  0.9936461388074291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "48 0.020165729126899807 0.25\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9900095424288973\n",
      "recall :  0.9916911045943304\n",
      "precision : 0.9950956351152526\n",
      "g_mean :  0.9933919113645135\n",
      "RS :  0.9965786901270772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "39 0.02078996342482738 0.17\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9879479507341173\n",
      "recall :  0.9917194349732099\n",
      "precision : 0.994140625\n",
      "g_mean :  0.9929292919986367\n",
      "RS :  0.9975645396980029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:04,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "42 0.02049967167863024 0.0715\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9912904808635918\n",
      "recall :  0.9960745829244357\n",
      "precision : 0.9926650366748166\n",
      "g_mean :  0.9943683484451512\n",
      "RS :  1.0034347399411188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "42 0.016037828248424098 0.19\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9950873286479717\n",
      "recall :  0.9926936190940088\n",
      "precision : 0.9965770171149144\n",
      "g_mean :  0.9946334228376383\n",
      "RS :  0.9961032635168047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:04<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "37 0.020501412410631248 0.64671990156695\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.98488824101069\n",
      "recall :  0.9902818270165209\n",
      "precision : 0.9941463414634146\n",
      "g_mean :  0.9922122027803227\n",
      "RS :  0.9961127308066083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:05<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "47 0.016180707689053823 0.25\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9925113491486649\n",
      "recall :  0.9931607230092818\n",
      "precision : 0.9965686274509804\n",
      "g_mean :  0.9948632160089061\n",
      "RS :  0.9965803615046409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:05<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "29 0.015566506450514411 0.0155\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9936565935358415\n",
      "recall :  0.9956246961594555\n",
      "precision : 0.9951409135082604\n",
      "g_mean :  0.9953827754424449\n",
      "RS :  1.0004861448711717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:06<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "45 0.014178259214331336 0.185\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9950076761244101\n",
      "recall :  0.9951100244498777\n",
      "precision : 0.9965719882468168\n",
      "g_mean :  0.9958407380652556\n",
      "RS :  0.9985330073349633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Best paramater\n",
      "57 0.015389842954095238 0.027\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AUC :  0.9953229911197748\n",
      "recall :  0.9883040935672515\n",
      "precision : 0.9990147783251232\n",
      "g_mean :  0.9936450044924996\n",
      "RS :  0.9892787524366471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# K:再標本化の回数 SIZE:再標本化されたもののサンプルサイズ\n",
    "K = n_estimators\n",
    "SIZE = int(len(X) * max_samples)\n",
    "\n",
    "# 予測に必要なパラメータ\n",
    "select_columns = [0] * K\n",
    "result_scaler = [0] * K\n",
    "result_inv_C = [0] * K\n",
    "threshold = [0] * K\n",
    "\n",
    "for i in tqdm(range(K)):\n",
    "    # bootstrap sampling\n",
    "    resampled_data_x, resampled_data_y = resample(X_train, y_train, n_samples = SIZE)\n",
    "    random_s = random.sample(list(resampled_data_x.columns), 7)\n",
    "    resampled_data_x = resampled_data_x[random_s]\n",
    "\n",
    "    result_scaler[i], result_inv_C[i], select_columns[i] = fit_MTS(resampled_data_x, resampled_data_y)\n",
    "\n",
    "    if result_scaler[i] != 0:\n",
    "        y_pred = predict_MTS(resampled_data_x, result_scaler[i], result_inv_C[i], select_columns[i])\n",
    "    else:\n",
    "        y_pred = resampled_data_x[select_columns[i]]\n",
    "\n",
    "    threshold[i] = determine_threshold(resampled_data_y, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 1, 3, 1, Int64Index([1, 4], dtype='int64'), 0, 5, 1, 6]\n",
      "[0, 0, 0, 0, 0, StandardScaler(), 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, array([[ 3.11232901, -2.58418404],\n",
      "       [-2.58418404,  3.11232901]]), 0, 0, 0, 0]\n",
      "[0.0895, 0.25, 0.17, 0.0715, 0.19, 0.64671990156695, 0.25, 0.0155, 0.185, 0.027]\n"
     ]
    }
   ],
   "source": [
    "print(select_columns)\n",
    "print(result_scaler)\n",
    "print(result_inv_C)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## とりあえずあとは予測だけ\n",
    "- 新しいデータをそれぞれの弱学習器に入れる\n",
    "- 学習時に用いた変数を用いてマハラノビス距離を計算する\n",
    "- 学習時に求めた閾値を超えたらTrue，超えなかったらFalseを各弱学習器で出力\n",
    "- それらを集計（投票）して各データの出力を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_MTSBag(X, scaler, inv_C, select_columns, threshold):\n",
    "    result = np.ndarray((K, len(X_test)), dtype=bool)\n",
    "    for i in range(K):\n",
    "        if scaler[i] != 0:\n",
    "            Z = scaler[i].transform(X[select_columns[i]])\n",
    "            MD = cal_MD(Z, inv_C[i])\n",
    "            result[i] = MD > threshold[i]\n",
    "        else:\n",
    "            result[i] = X[select_columns[i]] > threshold[i]\n",
    "    return result.sum(axis=0) / K, result.sum(axis=0) > (K/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC :  0.9582216808769792\n",
      "confusion_matrix : \n",
      "[[ 13   2]\n",
      " [ 16 805]]\n",
      "accuracy_score :  0.9784688995215312\n",
      "precision_score :  0.9975216852540273\n",
      "recall_score :  0.9805115712545676\n",
      "g_mean :  0.9889800579227725\n",
      "RS :  0.9829476248477466\n"
     ]
    }
   ],
   "source": [
    "y_proba, y_pred = predict_MTSBag(X_test, result_scaler, result_inv_C, select_columns, threshold)\n",
    "\n",
    "print('AUC : ', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion_matrix : ')\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy_score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print('precision_score : ', precision_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print('recall_score : ', recall_score(y_test, y_pred))\n",
    "\n",
    "g_mean = np.sqrt(recall_score(y_test, y_pred) * precision_score(y_test, y_pred))\n",
    "print('g_mean : ', g_mean)\n",
    "\n",
    "RS = recall_score(y_test, y_pred) / precision_score(y_test, y_pred)\n",
    "print('RS : ', RS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "clf = lightgbm.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC :  0.9900933820544051\n",
      "confusion_matrix : \n",
      "[[ 10   5]\n",
      " [  7 814]]\n",
      "accuracy_score :  0.9856459330143541\n",
      "precision_score :  0.9938949938949939\n",
      "recall_score :  0.9914738124238733\n",
      "g_mean :  0.9926836649940765\n",
      "RS :  0.9975639464068209\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('AUC : ', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion_matrix : ')\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy_score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print('precision_score : ', precision_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print('recall_score : ', recall_score(y_test, y_pred))\n",
    "\n",
    "g_mean = np.sqrt(recall_score(y_test, y_pred) * precision_score(y_test, y_pred))\n",
    "print('g_mean : ', g_mean)\n",
    "\n",
    "RS = recall_score(y_test, y_pred) / precision_score(y_test, y_pred)\n",
    "print('RS : ', RS)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7e6621f5c0e725993c5f5dd1734f3da8dc8c958ed2c46496e37b878d46070df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('convenient': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
